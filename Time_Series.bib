Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Depuru2011,
abstract = {Smart meter is an advanced energy meter that measures consumption of electrical energy providing additional information compared to a conventional energy meter. Integration of smart meters into electricity grid involves implementation of a variety of techniques and software, depending on the features that the situation demands. Design of a smart meter depends on the requirements of the utility company as well as the customer. This paper discusses various features and technologies that can be integrated with a smart meter. In fact, deployment of smart meters needs proper selection and implementation of a communication network satisfying the security standards of smart grid communication. This paper outlines various issues and challenges involved in design, deployment, utilization, and maintenance of the smart meter infrastructure. In addition, several applications and advantages of smart meter, in the view of future electricity market are discussed in detail. This paper explains the importance of introducing smart meters in developing countries. In addition, the status of smart metering in various countries is also illustrated. {\textcopyright} 2011 IEEE.},
author = {Depuru, Soma Shekara Sreenadh Reddy and Wang, Lingfeng and Devabhaktuni, Vijay and Gudi, Nikhil},
doi = {10.1109/PSCE.2011.5772451},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/05772451.pdf:pdf},
isbn = {9781612847870},
journal = {2011 IEEE/PES Power Systems Conference and Exposition, PSCE 2011},
keywords = {Communication technology,deployment,design,issues,protocols,smart meters},
pages = {1--7},
publisher = {IEEE},
title = {{Smart meters for power grid - Challenges, issues, advantages and status}},
year = {2011}
}
@article{Greff2017,
abstract = {Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: Speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs ≈15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.},
archivePrefix = {arXiv},
arxivId = {1503.04069},
author = {Greff, Klaus and Srivastava, Rupesh K. and Koutnik, Jan and Steunebrink, Bas R. and Schmidhuber, Jurgen},
doi = {10.1109/TNNLS.2016.2582924},
eprint = {1503.04069},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/1503.04069.pdf:pdf},
issn = {21622388},
journal = {IEEE Transactions on Neural Networks and Learning Systems},
keywords = {Functional ANalysis Of VAriance (fANOVA),long short-term memory (LSTM),random search,recurrent neural networks,sequence learning},
number = {10},
pages = {2222--2232},
pmid = {27411231},
title = {{LSTM: A Search Space Odyssey}},
volume = {28},
year = {2017}
}
@article{loadforecastingmoor,
author = {Espinoza, Marcelo and Suykens, Johan and Belmans, Ronnie and {De Moor}, Bart},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/04303474.pdf:pdf},
journal = {IEEE control systems magazine},
number = {October 2007},
pages = {43--57},
title = {{Electric Load Forecasting}},
year = {2007}
}
@article{NarjesFallah2018,
abstract = {Energy management systems are designed to monitor, optimize, and control the smart grid energy market. Demand-side management, considered as an essential part of the energy management system, can enable utility market operators to make better management decisions for energy trading between consumers and the operator. In this system, a priori knowledge about the energy load pattern can help reshape the load and cut the energy demand curve, thus allowing a better management and distribution of the energy in smart grid energy systems. Designing a computationally intelligent load forecasting (ILF) system is often a primary goal of energy demand management. This study explores the state of the art of computationally intelligent (i.e., machine learning) methods that are applied in load forecasting in terms of their classification and evaluation for sustainable operation of the overall energy management system. More than 50 research papers related to the subject identified in existing literature are classified into two categories: namely the single and the hybrid computational intelligence (CI)-based load forecasting technique. The advantages and disadvantages of each individual techniques also discussed to encapsulate them into the perspective into the energy management research. The identified methods have been further investigated by a qualitative analysis based on the accuracy of the prediction, which confirms the dominance of hybrid forecasting methods, which are often applied as metaheurstic algorithms considering the different optimization techniques over single model approaches. Based on extensive surveys, the review paper predicts a continuous future expansion of such literature on different CI approaches and their optimizations with both heuristic and metaheuristic methods used for energy load forecasting and their potential utilization in real-time smart energy management grids to address future challenges in energy demand management.},
author = {{Narjes Fallah}, Seyedeh and {Chand Deo}, Ravinesh and Shojafar, Mohammad and Conti, Mauro and Shamshirband, Shahaboddin},
doi = {10.3390/en11030596},
file = {:C$\backslash$:/Users/Stijn/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Narjes Fallah et al. - 2018 - Computational Intelligence Approaches for Energy Load Forecasting in Smart Energy Management Grids State o.pdf:pdf},
keywords = {computational intelligence (CI),demand-side management,load forecasting,machine learning,smart grid},
pages = {596},
title = {{Computational Intelligence Approaches for Energy Load Forecasting in Smart Energy Management Grids: State of the Art, Future Challenges, and Research Directions}},
url = {www.mdpi.com/journal/energies},
volume = {11},
year = {2018}
}
@article{Hoverstad2015,
abstract = {This paper studies data-driven short-term load forecasting, where historic data are used to predict the expected load for the next 24 h. Our focus is to simplify and automate the estimation and analysis of various forecasting models. We propose a three-stage approach to load forecasting, consisting of preprocessing, forecasting, and postprocessing, where the forecasting stage uses evolution to automatically set the parameters for each model. In our implementation, the preprocessing stage includes removal of daily and weekly seasonality by a nonparametric method. This seasonal pattern is added in the postprocessing stage. The system allows for easy exploration of several forecasting models, without the need to have in-depth knowledge of how to obtain the best performance for each model. We apply the method to several forecasting algorithms and on three datasets: 1) distribution substation; 2) GEFCom 2012; and 3) a transmission level dataset. We find that the forecasting algorithms considered produce significantly more accurate forecasts when combined with our proposed preprocessing stage compared with applying the same algorithms directly on the raw data. We also find that the parameter values chosen by evolution often provide insights into the interplay between the different datasets and forecast models. Software is available online.},
author = {Hoverstad, Boye A. and Tidemann, Axel and Langseth, Helge and Ozturk, Pinar},
doi = {10.1109/TSG.2015.2395822},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/IEEE{\_}Short- term load forecasting with seasonal decomposition using evolution for parameter tuning.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Artificial intelligence,Genetic algorithms,Load forecasting},
number = {4},
pages = {1904--1913},
title = {{Short-Term Load Forecasting With Seasonal Decomposition Using Evolution for Parameter Tuning}},
volume = {6},
year = {2015}
}
@book{Teuwen2019,
abstract = {In this chapter we introduce convolutional neural networks by starting with multilinear perceptrons, and proceed by explaining backpropagation. Using this we proceed to convolutional neural networks, explain the concept of convolutions, and provide practical methodologies to train such networks in the classification and segmentation setting.},
author = {Teuwen, Jonas and Moriakov, Nikita},
booktitle = {Handbook of Medical Image Computing and Computer Assisted Intervention},
doi = {10.1016/B978-0-12-816176-0.00025-9},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/Chapter-20---Convolutional-{\_}2020{\_}Handbook-of-Medical-Image-Computing-and-Com.pdf:pdf},
isbn = {9780128161760},
keywords = {Backpropagation,Convnets,Convolutional neural networks,Methodology,Multilinear perceptron},
pages = {481--501},
publisher = {Elsevier Inc.},
title = {{Convolutional neural networks}},
url = {https://doi.org/10.1016/B978-0-12-816176-0.00025-9},
year = {2019}
}
@article{Chung2014,
abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
archivePrefix = {arXiv},
arxivId = {1412.3555},
author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
eprint = {1412.3555},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/1412.3555v1.pdf:pdf},
pages = {1--9},
title = {{Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}},
url = {http://arxiv.org/abs/1412.3555},
year = {2014}
}
@article{Kong2019,
abstract = {As the power system is facing a transition toward a more intelligent, flexible, and interactive system with higher penetration of renewable energy generation, load forecasting, especially short-term load forecasting for individual electric customers plays an increasingly essential role in the future grid planning and operation. Other than aggregated residential load in a large scale, forecasting an electric load of a single energy user is fairly challenging due to the high volatility and uncertainty involved. In this paper, we propose a long short-term memory (LSTM) recurrent neural network-based framework, which is the latest and one of the most popular techniques of deep learning, to tackle this tricky issue. The proposed framework is tested on a publicly available set of real residential smart meter data, of which the performance is comprehensively compared to various benchmarks including the state-of-the-arts in the field of load forecasting. As a result, the proposed LSTM approach outperforms the other listed rival algorithms in the task of short-term load forecasting for individual residential households.},
author = {Kong, Weicong and Dong, Zhao Yang and Jia, Youwei and Hill, David J. and Xu, Yan and Zhang, Yuan},
doi = {10.1109/TSG.2017.2753802},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/IEEE{\_}Short-Term Residential Load Forecasting Based on LSTM Recurrent Neural Network.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Short-term load forecasting,deep learning,recurrent neural network,residential load forecasting},
number = {1},
pages = {841--851},
publisher = {IEEE},
title = {{Short-Term Residential Load Forecasting Based on LSTM Recurrent Neural Network}},
volume = {10},
year = {2019}
}
@misc{FneishMo,
author = {Fneish, Mohammad},
title = {{Keras{\_}LSTM{\_}Diagram: Understanding Keras Recurrent Nets' structure and data flow in a single diagram.}},
url = {https://github.com/MohammadFneish7/Keras{\_}LSTM{\_}Diagram},
urldate = {2021-04-20}
}
@book{Czum2020,
author = {{Zhang, Aston Lipton, Zachary Li}, Mu and Smola, Alexander},
doi = {10.1016/j.jacr.2020.02.005},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/d2l-en.pdf:pdf},
issn = {1558349X},
number = {5},
pages = {637--638},
pmid = {32142636},
title = {{Dive Into Deep Learning}},
volume = {17},
year = {2020}
}
@misc{Helmus,
author = {Helmus, John},
title = {{Anaconda | Understanding Conda and Pip}},
url = {https://www.anaconda.com/blog/understanding-conda-and-pip},
urldate = {2021-05-12}
}
@article{Sajjad2020,
abstract = {Electric energy forecasting domain attracts researchers due to its key role in saving energy resources, where mainstream existing models are based on Gradient Boosting Regression (GBR), Artificial Neural Networks (ANNs), Extreme Learning Machine (ELM) and Support Vector Machine (SVM). These models encounter high-level of non-linearity between input data and output predictions and limited adoptability in real-world scenarios. Meanwhile, energy forecasting domain demands more robustness, higher prediction accuracy and generalization ability for real-world implementation. In this paper, we achieve the mentioned tasks by developing a hybrid sequential learning-based energy forecasting model that employs Convolution Neural Network (CNN) and Gated Recurrent Units (GRU) into a unified framework for accurate energy consumption prediction. The proposed framework has two major phases: (1) data refinement and (2) training, where the data refinement phase applies preprocessing strategies over raw data. In the training phase, CNN features are extracted from input dataset and fed in to GRU, that is selected as optimal and observed to have enhanced sequence learning abilities after extensive experiments. The proposed model is an effective alternative to the previous hybrid models in terms of computational complexity as well prediction accuracy, due to the representative features' extraction potentials of CNNs and effectual gated structure of multi-layered GRU. The experimental evaluation over existing energy forecasting datasets reveal the better performance of our method in terms of preciseness and efficiency. The proposed method achieved the smallest error rate on Appliances Energy Prediction (AEP) and Individual Household Electric Power Consumption (IHEPC) datasets, when compared to other baseline models.},
author = {Sajjad, Muhammad and Khan, Zulfiqar Ahmad and Ullah, Amin and Hussain, Tanveer and Ullah, Waseem and Lee, Mi Young and Baik, Sung Wook},
doi = {10.1109/ACCESS.2020.3009537},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/09141253.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {CNN,CNN-GRU,GRU,LSTM,deep learning,electricity consumption prediction,energy forecasting,short-term load forecasting},
pages = {143759--143768},
title = {{A Novel CNN-GRU-Based Hybrid Approach for Short-Term Residential Load Forecasting}},
volume = {8},
year = {2020}
}
@article{Hammer2000,
abstract = {The capability of recurrent neural networks of approximating functions from lists of real vectors to a real vector space is examined. Any measurable function can be approximated in probability. Additionally, bounds on the resources sufficient for an approximation can be derived in interesting cases. On the contrary, there exist computable mappings on symbolic data which cannot be approximated in the maximum norm. For restricted input length, some continuous functions on real-valued sequences need a number of neurons increasing at least linearly in the input length. On unary sequences, any mapping with bounded range can be approximated in the maximum norm. Consequently, standard sigmoidal networks can compute any mapping on offline inputs as a computational model. (C) 2000 Elsevier Science B.V.},
author = {Hammer, Barbara},
doi = {10.1016/S0925-2312(99)00174-5},
file = {::},
issn = {09252312},
journal = {Neurocomputing},
keywords = {Computational capability,Recurrent neural networks,Sigmoidal networks,Universal approximation},
month = {mar},
number = {1-4},
pages = {107--123},
publisher = {Elsevier Science B.V.},
title = {{On the approximation capability of recurrent neural networks}},
volume = {31},
year = {2000}
}
@misc{Lago2020,
author = {Lago, Jesus},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/A ratios and clustering based approach to forecast electricity consumption.pdf:pdf},
title = {{A ratios and clustering based approach to forecast electricity consumption}},
year = {2020}
}
@misc{Olah,
author = {Olah, Christopher},
title = {{Understanding LSTM Networks}},
url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
urldate = {2021-04-18}
}
@misc{Nielsen2015,
author = {Nielsen, Michael A.},
publisher = {Determination Press},
title = {{Neural Networks and Deep Learning}},
url = {http://neuralnetworksanddeeplearning.com},
year = {2015}
}
@article{Hutter2014,
abstract = {The performance of many machine learning methods depends critically on hyperparameter settings. Sophisticated Bayesian optimization methods have recently achieved considerable successes in optimizing these hyperparameters, in several cases surpassing the performance of human experts. However, blind reliance on such methods can leave end users without insight into the relative importance of different hyperparameters and their interactions. This paper describes efficient methods that can be used to gain such insight, leveraging random forest models fit on the data already gathered by Bayesian optimization. We first introduce a novel, linear-time algorithm for computing marginals of random forest predictions and then show how to leverage these predictions within a functional ANOVA framework, to quantify the importance of both single hyperparameters and of interactions between hyperparameters. We conducted experiments with prominent machine learning frameworks and state-of-the-art solvers for combinatorial problems. We show that our methods provide insight into the relationship between hyperparameter settings and performance, and demonstrate that-even in very high- dimensional cases-most performance variation is attributable to just a few hyperparameters.},
author = {Hutter, Frank and Hoos, Hoiger and Leyton-Brown, Kevin},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/hutter14.pdf:pdf},
isbn = {9781634393973},
journal = {31st International Conference on Machine Learning, ICML 2014},
keywords = {Hyperparameter optimization, Random forests, Sensi},
pages = {1130--1144},
title = {{An efficient approach for assessing hyperparameter importance}},
volume = {2},
year = {2014}
}
@article{ANNRNN,
author = {Suykens, Johan},
file = {:C$\backslash$:/Users/Stijn/Downloads/6ann{\_}lecture2019(3).pdf:pdf},
title = {{Recurrent neural networks - ANN lecture}},
volume = {0},
year = {2021}
}
@article{Kim2019,
abstract = {The rapid increase in human population and development in technology have sharply raised power consumption in today's world. Since electricity is consumed simultaneously as it is generated at the power plant, it is important to accurately predict the energy consumption in advance for stable power supply. In this paper, we propose a CNN-LSTM neural network that can extract spatial and temporal features to effectively predict the housing energy consumption. Experiments have shown that the CNN-LSTM neural network, which combines convolutional neural network (CNN) and long short-term memory (LSTM), can extract complex features of energy consumption. The CNN layer can extract the features between several variables affecting energy consumption, and the LSTM layer is appropriate for modeling temporal information of irregular trends in time series components. The proposed CNN-LSTM method achieves almost perfect prediction performance for electric energy consumption that was previously difficult to predict. Also, it records the smallest value of root mean square error compared to the conventional forecasting methods for the dataset on individual household power consumption. The empirical analysis of the variables confirms what affects to forecast the power consumption most.},
author = {Kim, Tae Young and Cho, Sung Bae},
doi = {10.1016/j.energy.2019.05.230},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/1-s2.0-S0360544219311223-main.pdf:pdf},
issn = {03605442},
journal = {Energy},
keywords = {Convolutional neural network,Deep learning,Electric energy consumption,Long short-term memory},
pages = {72--81},
publisher = {Elsevier Ltd},
title = {{Predicting residential energy consumption using CNN-LSTM neural networks}},
url = {https://doi.org/10.1016/j.energy.2019.05.230},
volume = {182},
year = {2019}
}
@article{Mele1993,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different “thinned” networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets. Keywords:},
author = {Srivastave, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/srivastava14a.pdf:pdf},
journal = {Joernal of Machine Learning Research 15},
keywords = {deep learning,model combination,neural networks,regularization},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting Nitish}},
year = {2014}
}
@article{Shi2018,
abstract = {The key challenge for household load forecasting lies in the high volatility and uncertainty of load profiles. Traditional methods tend to avoid such uncertainty by load aggregation (to offset uncertainties), customer classification (to cluster uncertainties) and spectral analysis (to filter out uncertainties). This paper, for the first time, aims to directly learn the uncertainty by applying a new breed of machine learning algorithms-deep learning. However, simply adding layers in neural networks will cap the forecasting performance due to the occurrence of over-fitting. A novel pooling-based deep recurrent neural network is proposed in this paper which batches a group of customers' load profiles into a pool of inputs. Essentially the model could address the over-fitting issue by increasing data diversity and volume. This paper reports the first attempts to develop a bespoke deep learning application for household load forecasting and achieved preliminary success. The developed method is implemented on Tensorflow deep learning platform and tested on 920 smart metered customers from Ireland. Compared with the state-of-The-Art techniques in household load forecasting, the proposed method outperforms ARIMA by 19.5{\%}, SVR by 13.1{\%} and classical deep RNN by 6.5{\%} in terms of RMSE.},
author = {Shi, Heng and Xu, Minghao and Li, Ran},
doi = {10.1109/TSG.2017.2686012},
file = {:D$\backslash$:/Onedrive/Leuven/Final project/Literatuur/Deep Learning for Household Load Forecasting—A Novel Pooling Deep RNN.pdf:pdf},
issn = {19493053},
journal = {IEEE Transactions on Smart Grid},
keywords = {Big data,deep learning,load forecasting,long short-Term memory,machine learning,neural network,smart meter},
number = {5},
pages = {5271--5280},
publisher = {IEEE},
title = {{Deep Learning for Household Load Forecasting-A Novel Pooling Deep RNN}},
volume = {9},
year = {2018}
}
