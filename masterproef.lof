\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\babel@toc {english}{}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {1.1}{\ignorespaces Electricity grid (Source: KU Leuven thesis proposal).\relax }}{2}{figure.caption.9}%
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces The amount of NaN values in all the 3248 load signals.\relax }}{8}{figure.caption.11}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Resulting time serie of the month March after imputation of the missing data.\relax }}{9}{figure.caption.13}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Resulting month of March after substitution of the missing values by the mean value of the measurements. \relax }}{10}{figure.caption.14}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Comparison of series with and without zero load days.\relax }}{11}{figure.caption.15}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces The maximum differences between the maximum and minimum weekly rolling mean for all the 261 different load signals.\relax }}{12}{figure.caption.16}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Removed load signal with a shift in the rolling mean.\relax }}{12}{figure.caption.17}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces The seasonality of the electrical load during the year 2017. The blue line indicates the average load signal. \relax }}{14}{figure.caption.18}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Error between different pairs of weekdays.\relax }}{15}{figure.caption.19}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Comparison between bank holiday and business day electrical consumption.\relax }}{16}{figure.caption.20}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Error between a bank holiday and other days of the week.\relax }}{16}{figure.caption.21}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Relation between normalized daily consumption and daily temperature.\relax }}{18}{figure.caption.22}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces Influence of the dwelling type (sample size: 1702) and number of bedrooms (sample size: 1859). \relax }}{20}{figure.caption.23}%
\addvspace {10pt}
\contentsline {figure}{\numberline {3.1}{\ignorespaces Figure of a MLP (source \cite {Czum2020}).\relax }}{24}{figure.caption.24}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Vanilla RNN,(source: \cite {Czum2020}).\relax }}{25}{figure.caption.25}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces Exponential decrease of the gradient size of a simple RNN (red) or a LSTM (blue) (source: \cite {Teuwen2019}).\relax }}{27}{figure.caption.26}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces A LSTM cell that is repeated over time (source: \cite {Olah}).\relax }}{27}{figure.caption.27}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces A GRU cell that is repeated over time (source: \cite {Olah}).\relax }}{28}{figure.caption.28}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Comparing different methods in \cite {Shi2018}.\relax }}{31}{figure.caption.29}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Influence of the number of layers and the pooling method(Source: \cite {Shi2018}).\relax }}{32}{figure.caption.30}%
\contentsline {figure}{\numberline {3.8}{\ignorespaces Different approaches tried in \cite {Kong2019} and their performance in making $ 29,808 $ predictions.\relax }}{33}{figure.caption.31}%
\contentsline {figure}{\numberline {3.9}{\ignorespaces Comparison between LSTM and CNN-LSTM. (source: \cite {Kim2019})\relax }}{34}{figure.caption.32}%
\contentsline {figure}{\numberline {3.10}{\ignorespaces The importance of the different inputs based on the average class activation score. (source: \cite {Kim2019})\relax }}{35}{figure.caption.33}%
\addvspace {10pt}
\contentsline {figure}{\numberline {4.1}{\ignorespaces The electrical consumption in $ 2017 $ for the three selected series. \relax }}{38}{figure.caption.34}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Daily predictions of two baseline models. (Blue: True / Orange: Prediction) \relax }}{44}{figure.caption.40}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces The generation of inputs for a stateless model (Source: \cite {FneishMo}).\relax }}{48}{figure.caption.45}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces The generation of inputs for a stateful model (Source: \cite {FneishMo}).\relax }}{48}{figure.caption.46}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces The flow of functions that are executed in order during the prediction process with LSTM models.\relax }}{50}{figure.caption.50}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Model 1 - stateless model with as input a subserie of N time steps and $ \bm {C}_{i} \in \mathbb {R}^{m} $, $ \bm {H}_{j} \in \mathbb {R}^{n} $, $ \bm {X}_{k} \in \mathbb {R}^{59} $, $ \hat {y} \in \mathbb {R}^{1} $.\relax }}{51}{figure.caption.52}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Model 2 - stateless model with as input a serie of N time steps and $ \bm {C}_{i} \in \mathbb {R}^{m} $, $ \bm {H}_{j} \in \mathbb {R}^{n} $, $ \bm {X}_{k} \in \mathbb {R}^{59} $, $ \hat {y} \in \mathbb {R}^{1} $.\relax }}{51}{figure.caption.53}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Model 3 - stateful model that connects single LSTM blocks and $ \bm {C}_{i} \in \mathbb {R}^{m} $, $ \bm {H}_{j} \in \mathbb {R}^{n} $, $ \bm {X}_{k} \in \mathbb {R}^{59} $, $ \hat {y} \in \mathbb {R}^{1} $.\relax }}{52}{figure.caption.54}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces Results of the sensitivity analysis on the size of the regularization parameter and the dropout rate according to MAE. (Legend: \textit {r\_D}: regularization size of weights of DENSE layer, \textit {r\_r\_L}: regularization size of recurrent weight of LSTM, \textit {r\_L}: regularization size of input weights of LSTM, \textit {d\_L}: dropout rate of inputs LSTM, \textit {r\_d\_L}: dropout rate of hidden states LSTM, \textit {d\_D}: dropout rate of DENSE layer, \textit {or}: best performing serie from phase one)\relax }}{57}{figure.caption.60}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces The MAE on the validation set in function of the learning rate size.\relax }}{58}{figure.caption.61}%
\addvspace {10pt}
\contentsline {figure}{\numberline {5.1}{\ignorespaces The evolution of the MSE on the training and validation sets.\relax }}{64}{figure.caption.68}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces The MAE performance on all the days of the test set for Serie 1.\relax }}{65}{figure.caption.69}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces The MAE performance on all the days of the test set for Serie 2.\relax }}{65}{figure.caption.70}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces The MAE performance on all the days of the test set for Serie 3.\relax }}{66}{figure.caption.71}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces The prediction results of the different models on 7th December. (True values: blue/ Prediction: orange)\relax }}{69}{figure.caption.73}%
\addvspace {10pt}
\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {B.1}{\ignorespaces An example histogram of the consumption in [kWh] versus count [-] used during MAPE forecast.\relax }}{79}{figure.caption.75}%
\contentsline {figure}{\numberline {B.2}{\ignorespaces Results of the sensitivity analysis on the size of the regularization parameter and the dropout rate according to MAE.(Legend: \textit {r\_D}: regularization size of weights of DENSE layer, \textit {r\_r\_L}: regularization size of recurrent weight of LSTM, \textit {r\_L}: regularization size of input weights of LSTM, \textit {d\_L}: dropout rate of inputs LSTM, \textit {r\_d\_L}: dropout rate of hidden states LSTM, \textit {d\_D}: dropout rate of DENSE layer, \textit {or}: best performing serie from phase one)\relax }}{81}{figure.caption.78}%
\contentsline {figure}{\numberline {B.3}{\ignorespaces The evaluation of the error on the validation set in function of the learning rate size.\relax }}{82}{figure.caption.79}%
\contentsline {figure}{\numberline {B.4}{\ignorespaces Results of the sensitivity analysis on the size of regulation parameter and the dropout rate with respect to the mean absolute error.(Legend: \textit {r\_r\_L}: regularization size of recurrent weight of LSTM, \textit {r\_L}: regularization size of input weights of LSTM and \textit {or}: best performing serie from phase one)\relax }}{84}{figure.caption.82}%
\contentsline {figure}{\numberline {B.5}{\ignorespaces The evaluation of the error on the validation set in function of the learning rate size.\relax }}{85}{figure.caption.83}%
\addvspace {10pt}
\contentsline {figure}{\numberline {C.1}{\ignorespaces The MAE performance for the different days in the test set for Serie 1.\relax }}{87}{figure.caption.84}%
\contentsline {figure}{\numberline {C.2}{\ignorespaces The MAE performance for the different days in the test set for Serie 2.\relax }}{88}{figure.caption.85}%
\contentsline {figure}{\numberline {C.3}{\ignorespaces The MAE performance for the different days in the test set for Serie 3.\relax }}{89}{figure.caption.86}%
