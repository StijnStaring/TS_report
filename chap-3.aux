\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Forecasting the daily electricity consumption}{31}{chapter.4}\protected@file@percent }
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{cha:Forecasting the daily electricity consumption}{{\M@TitleReference {4}{Forecasting the daily electricity consumption}}{31}{Forecasting the daily electricity consumption}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Preprocessing}{31}{section.4.1}\protected@file@percent }
\newlabel{s:Preprocessing}{{\M@TitleReference {4.1}{Preprocessing}}{31}{Preprocessing}{section.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The electrical consumption in $ 2017 $ for the three selected series. \relax }}{32}{figure.caption.29}\protected@file@percent }
\newlabel{fig:three_series}{{\M@TitleReference {4.1}{The electrical consumption in $ 2017 $ for the three selected series. \relax }}{32}{The electrical consumption in $ 2017 $ for the three selected series. \relax }{figure.caption.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Summarizing characteristics about the selected series.\relax }}{32}{table.caption.30}\protected@file@percent }
\newlabel{tab:summ_data}{{\M@TitleReference {4.1}{Summarizing characteristics about the selected series.\relax }}{32}{Summarizing characteristics about the selected series.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Error metrics}{33}{section.4.2}\protected@file@percent }
\newlabel{eq:MSE}{{4.1}{33}{Error metrics}{equation.4.2.1}{}}
\newlabel{eq:MAPE}{{4.2}{33}{Error metrics}{equation.4.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Microsoft Azure cloud}{33}{section.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Specifications of different CPU's and GPU used.\relax }}{33}{table.caption.31}\protected@file@percent }
\newlabel{tab:CPU}{{\M@TitleReference {4.2}{Specifications of different CPU's and GPU used.\relax }}{33}{Specifications of different CPU's and GPU used.\relax }{table.caption.31}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Baseline models}{34}{section.4.4}\protected@file@percent }
\newlabel{s:Baseline models}{{\M@TitleReference {4.4}{Baseline models}}{34}{Baseline models}{section.4.4}{}}
\citation{Kong2019}
\citation{Kong2019}
\newlabel{eq:model_mape}{{4.3}{36}{Baseline models}{equation.4.4.3}{}}
\newlabel{eq:model_mape_solve}{{4.4}{36}{Baseline models}{equation.4.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Results of baseline models}{37}{subsection.4.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Baseline results for Serie $ 1 $ tested on $ 31 $ days of December.\relax }}{37}{table.caption.32}\protected@file@percent }
\newlabel{tab:summ_data_serie1}{{\M@TitleReference {4.3}{Baseline results for Serie $ 1 $ tested on $ 31 $ days of December.\relax }}{37}{Baseline results for Serie $ 1 $ tested on $ 31 $ days of December.\relax }{table.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Baseline results for Serie $ 2 $ tested on $ 12 $ days of December.\relax }}{37}{table.caption.33}\protected@file@percent }
\newlabel{tab:summ_data_serie2}{{\M@TitleReference {4.4}{Baseline results for Serie $ 2 $ tested on $ 12 $ days of December.\relax }}{37}{Baseline results for Serie $ 2 $ tested on $ 12 $ days of December.\relax }{table.caption.33}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces Baseline results for Serie $ 3 $ tested on $ 12 $ days of December.\relax }}{37}{table.caption.34}\protected@file@percent }
\newlabel{tab:summ_data_serie3}{{\M@TitleReference {4.5}{Baseline results for Serie $ 3 $ tested on $ 12 $ days of December.\relax }}{37}{Baseline results for Serie $ 3 $ tested on $ 12 $ days of December.\relax }{table.caption.34}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Daily predictions of two baseline models. (Blue: True / Orange: Prediction) \relax }}{38}{figure.caption.35}\protected@file@percent }
\newlabel{fig:baseline models 4 and 5}{{\M@TitleReference {4.2}{Daily predictions of two baseline models. (Blue: True / Orange: Prediction) \relax }}{38}{Daily predictions of two baseline models. (Blue: True / Orange: Prediction) \relax }{figure.caption.35}{}}
\citation{loadforecastingmoor}
\citation{Kong2019}
\@writefile{lot}{\contentsline {table}{\numberline {4.6}{\ignorespaces Relative performance over all the $ 261 $ time series with a full year of measurements.\relax }}{39}{table.caption.36}\protected@file@percent }
\newlabel{tab:summ_data_rel_performance}{{\M@TitleReference {4.6}{Relative performance over all the $ 261 $ time series with a full year of measurements.\relax }}{39}{Relative performance over all the $ 261 $ time series with a full year of measurements.\relax }{table.caption.36}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Deep LSTM models}{39}{section.4.5}\protected@file@percent }
\newlabel{s:Neural network models}{{\M@TitleReference {4.5}{Deep LSTM models}}{39}{Deep LSTM models}{section.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Different practical considerations of the models in Keras}{39}{subsection.4.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Inputs}{39}{section*.37}\protected@file@percent }
\newlabel{s:Inputs}{{\M@TitleReference {4.5.1}{Inputs}}{39}{Inputs}{section*.37}{}}
\citation{FneishMo}
\@writefile{toc}{\contentsline {subsubsection}{Batch size}{40}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Stateless versus Stateful}{40}{section*.39}\protected@file@percent }
\citation{FneishMo}
\citation{FneishMo}
\citation{FneishMo}
\citation{FneishMo}
\@writefile{toc}{\contentsline {subsubsection}{Initialization}{41}{section*.42}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces The generation of inputs for a stateless model. (source: \cite  {FneishMo})\relax }}{42}{figure.caption.40}\protected@file@percent }
\newlabel{fig:stateless_input}{{\M@TitleReference {4.3}{The generation of inputs for a stateless model. (source: \cite  {FneishMo})\relax }}{42}{The generation of inputs for a stateless model. (source: \cite {FneishMo})\relax }{figure.caption.40}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces The generation of inputs for a stateful model. (source: \cite  {FneishMo})\relax }}{42}{figure.caption.41}\protected@file@percent }
\newlabel{fig:stateful_input}{{\M@TitleReference {4.4}{The generation of inputs for a stateful model. (source: \cite  {FneishMo})\relax }}{42}{The generation of inputs for a stateful model. (source: \cite {FneishMo})\relax }{figure.caption.41}{}}
\@writefile{toc}{\contentsline {subsubsection}{Overfitting avoidance in Keras}{42}{section*.43}\protected@file@percent }
\citation{ANNRNN}
\@writefile{toc}{\contentsline {subsubsection}{Error metrics}{43}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Deep LSTM}{43}{subsection.4.5.2}\protected@file@percent }
\newlabel{s:LSTM_implementation}{{\M@TitleReference {4.5.2}{Deep LSTM}}{43}{Deep LSTM}{subsection.4.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces The flow of functions that are executed in order during the prediction process with LSTM models.\relax }}{43}{figure.caption.45}\protected@file@percent }
\newlabel{fig:model1}{{\M@TitleReference {4.5}{The flow of functions that are executed in order during the prediction process with LSTM models.\relax }}{43}{The flow of functions that are executed in order during the prediction process with LSTM models.\relax }{figure.caption.45}{}}
\citation{Kong2019}
\@writefile{toc}{\contentsline {subsubsection}{Model 1: Stateless with no flatten layer}{44}{section*.46}\protected@file@percent }
\newlabel{s:Model1}{{\M@TitleReference {4.5.2}{Model 1: Stateless with no flatten layer}}{44}{Model 1: Stateless with no flatten layer}{section*.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Model 1 - stateless model with as input a subserie of N time steps and $ \bm  {C}_{i} \in \mathbb  {R}^{m} $, $ \bm  {H}_{j} \in \mathbb  {R}^{n} $, $ \bm  {X}_{k} \in \mathbb  {R}^{59} $, $ \hat  {y} \in \mathbb  {R}^{1} $.\relax }}{44}{figure.caption.47}\protected@file@percent }
\newlabel{fig:model1}{{\M@TitleReference {4.6}{Model 1 - stateless model with as input a subserie of N time steps and $ \bm  {C}_{i} \in \mathbb  {R}^{m} $, $ \bm  {H}_{j} \in \mathbb  {R}^{n} $, $ \bm  {X}_{k} \in \mathbb  {R}^{59} $, $ \hat  {y} \in \mathbb  {R}^{1} $.\relax }}{44}{Model 1 - stateless model with as input a subserie of N time steps and $ \bm {C}_{i} \in \mathbb {R}^{m} $, $ \bm {H}_{j} \in \mathbb {R}^{n} $, $ \bm {X}_{k} \in \mathbb {R}^{59} $, $ \hat {y} \in \mathbb {R}^{1} $.\relax }{figure.caption.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}Model 2: Stateless with flatten layer}{44}{subsection.4.5.3}\protected@file@percent }
\newlabel{s:Model2}{{\M@TitleReference {4.5.3}{Model 2: Stateless with flatten layer}}{44}{Model 2: Stateless with flatten layer}{subsection.4.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Model 3: Stateful}{44}{subsection.4.5.4}\protected@file@percent }
\newlabel{s:Model3}{{\M@TitleReference {4.5.4}{Model 3: Stateful}}{44}{Model 3: Stateful}{subsection.4.5.4}{}}
\citation{Shi2018}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Model 2 - stateless model with as input a serie of N time steps and $ \bm  {C}_{i} \in \mathbb  {R}^{m} $, $ \bm  {H}_{j} \in \mathbb  {R}^{n} $, $ \bm  {X}_{k} \in \mathbb  {R}^{59} $, $ \hat  {y} \in \mathbb  {R}^{1} $.\relax }}{45}{figure.caption.48}\protected@file@percent }
\newlabel{fig:model2}{{\M@TitleReference {4.7}{Model 2 - stateless model with as input a serie of N time steps and $ \bm  {C}_{i} \in \mathbb  {R}^{m} $, $ \bm  {H}_{j} \in \mathbb  {R}^{n} $, $ \bm  {X}_{k} \in \mathbb  {R}^{59} $, $ \hat  {y} \in \mathbb  {R}^{1} $.\relax }}{45}{Model 2 - stateless model with as input a serie of N time steps and $ \bm {C}_{i} \in \mathbb {R}^{m} $, $ \bm {H}_{j} \in \mathbb {R}^{n} $, $ \bm {X}_{k} \in \mathbb {R}^{59} $, $ \hat {y} \in \mathbb {R}^{1} $.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Model 3 - stateful model that connects single LSTM blocks and $ \bm  {C}_{i} \in \mathbb  {R}^{m} $, $ \bm  {H}_{j} \in \mathbb  {R}^{n} $, $ \bm  {X}_{k} \in \mathbb  {R}^{59} $, $ \hat  {y} \in \mathbb  {R}^{1} $.\relax }}{45}{figure.caption.49}\protected@file@percent }
\newlabel{fig:model3}{{\M@TitleReference {4.8}{Model 3 - stateful model that connects single LSTM blocks and $ \bm  {C}_{i} \in \mathbb  {R}^{m} $, $ \bm  {H}_{j} \in \mathbb  {R}^{n} $, $ \bm  {X}_{k} \in \mathbb  {R}^{59} $, $ \hat  {y} \in \mathbb  {R}^{1} $.\relax }}{45}{Model 3 - stateful model that connects single LSTM blocks and $ \bm {C}_{i} \in \mathbb {R}^{m} $, $ \bm {H}_{j} \in \mathbb {R}^{n} $, $ \bm {X}_{k} \in \mathbb {R}^{59} $, $ \hat {y} \in \mathbb {R}^{1} $.\relax }{figure.caption.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}Parameter search}{46}{subsection.4.5.5}\protected@file@percent }
\newlabel{s:Parameter search}{{\M@TitleReference {4.5.5}{Parameter search}}{46}{Parameter search}{subsection.4.5.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.7}{\ignorespaces Parameters used during phase 1 for the two stateless models.\relax }}{46}{table.caption.50}\protected@file@percent }
\newlabel{tab:para_phase1}{{\M@TitleReference {4.7}{Parameters used during phase 1 for the two stateless models.\relax }}{46}{Parameters used during phase 1 for the two stateless models.\relax }{table.caption.50}{}}
\citation{Mele1993}
\@writefile{lot}{\contentsline {table}{\numberline {4.8}{\ignorespaces Different regularization added during phase 2.\relax }}{47}{table.caption.51}\protected@file@percent }
\newlabel{tab:regulation}{{\M@TitleReference {4.8}{Different regularization added during phase 2.\relax }}{47}{Different regularization added during phase 2.\relax }{table.caption.51}{}}
\citation{Greff2017}
\citation{Greff2017}
\@writefile{toc}{\contentsline {subsubsection}{Model 1: Stateless with no flatten layer}{48}{section*.52}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.9}{\ignorespaces Each value in this table shows the average error when the value of a chosen parameter was used, normalized by the biggest error of the possible values and finally subtracted by one. Therefore, each value shows a percentage of improvement with respect to the worst possible value for a chosen parameter for each serie during phase $ 1 $ of the parameter search. For example: when $ 20 $ LSTM units are chosen, this on average gave a $ 12.08\% $ lower MAE.\relax }}{49}{table.caption.53}\protected@file@percent }
\newlabel{tab:relative_performance_parameters_phase_one_model_one}{{\M@TitleReference {4.9}{Each value in this table shows the average error when the value of a chosen parameter was used, normalized by the biggest error of the possible values and finally subtracted by one. Therefore, each value shows a percentage of improvement with respect to the worst possible value for a chosen parameter for each serie during phase $ 1 $ of the parameter search. For example: when $ 20 $ LSTM units are chosen, this on average gave a $ 12.08\% $ lower MAE.\relax }}{49}{Each value in this table shows the average error when the value of a chosen parameter was used, normalized by the biggest error of the possible values and finally subtracted by one. Therefore, each value shows a percentage of improvement with respect to the worst possible value for a chosen parameter for each serie during phase $ 1 $ of the parameter search. For example: when $ 20 $ LSTM units are chosen, this on average gave a $ 12.08\% $ lower MAE.\relax }{table.caption.53}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.10}{\ignorespaces The values of the parameters that performed best for the three time series during phase $ 1 $ using model $ 1 $ based on the smallest sum of MAE errors during three runs.\relax }}{49}{table.caption.54}\protected@file@percent }
\newlabel{tab:best_performing_para_phase1}{{\M@TitleReference {4.10}{The values of the parameters that performed best for the three time series during phase $ 1 $ using model $ 1 $ based on the smallest sum of MAE errors during three runs.\relax }}{49}{The values of the parameters that performed best for the three time series during phase $ 1 $ using model $ 1 $ based on the smallest sum of MAE errors during three runs.\relax }{table.caption.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Results of the sensitivity analysis on the size of regulation parameter and the dropout rate with respect to the mean absolute error.(Legend: \textit  {r\_D}: regularization size of weights DENSE layer, \textit  {r\_r\_L}: regularization size of recurrent weight of LSTM, \textit  {r\_L}: regularization size of input weights of LSTM, \textit  {d\_L}: dropout rate of input states LSTM, \textit  {r\_d\_L}: dropout rate of recurrent states LSTM, \textit  {d\_D}: dropout rate of DENSE layer, \textit  {or}: best performing serie from phase one)\relax }}{50}{figure.caption.55}\protected@file@percent }
\newlabel{fig:sensitivity_model1}{{\M@TitleReference {4.9}{Results of the sensitivity analysis on the size of regulation parameter and the dropout rate with respect to the mean absolute error.(Legend: \textit  {r\_D}: regularization size of weights DENSE layer, \textit  {r\_r\_L}: regularization size of recurrent weight of LSTM, \textit  {r\_L}: regularization size of input weights of LSTM, \textit  {d\_L}: dropout rate of input states LSTM, \textit  {r\_d\_L}: dropout rate of recurrent states LSTM, \textit  {d\_D}: dropout rate of DENSE layer, \textit  {or}: best performing serie from phase one)\relax }}{50}{Results of the sensitivity analysis on the size of regulation parameter and the dropout rate with respect to the mean absolute error.(Legend: \textit {r\_D}: regularization size of weights DENSE layer, \textit {r\_r\_L}: regularization size of recurrent weight of LSTM, \textit {r\_L}: regularization size of input weights of LSTM, \textit {d\_L}: dropout rate of input states LSTM, \textit {r\_d\_L}: dropout rate of recurrent states LSTM, \textit {d\_D}: dropout rate of DENSE layer, \textit {or}: best performing serie from phase one)\relax }{figure.caption.55}{}}
\citation{Greff2017}
\@writefile{lot}{\contentsline {table}{\numberline {4.11}{\ignorespaces Final values obtained after the parameter search for model 1.\relax }}{51}{table.caption.57}\protected@file@percent }
\newlabel{tab:final_model1}{{\M@TitleReference {4.11}{Final values obtained after the parameter search for model 1.\relax }}{51}{Final values obtained after the parameter search for model 1.\relax }{table.caption.57}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces The evaluation of the error on the validation set in function of the learning rate size.\relax }}{52}{figure.caption.56}\protected@file@percent }
\newlabel{fig:learning_rate_model1}{{\M@TitleReference {4.10}{The evaluation of the error on the validation set in function of the learning rate size.\relax }}{52}{The evaluation of the error on the validation set in function of the learning rate size.\relax }{figure.caption.56}{}}
\@writefile{toc}{\contentsline {subsubsection}{Model 2: Stateless with flatten layer}{53}{section*.58}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.12}{\ignorespaces Final values obtained after the parameter search for model 2.\relax }}{53}{table.caption.59}\protected@file@percent }
\newlabel{tab:final_model2}{{\M@TitleReference {4.12}{Final values obtained after the parameter search for model 2.\relax }}{53}{Final values obtained after the parameter search for model 2.\relax }{table.caption.59}{}}
\@writefile{toc}{\contentsline {subsubsection}{Model 3: Stateful model}{54}{section*.60}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.13}{\ignorespaces Final values obtained after the parameter search for model 2.\relax }}{55}{table.caption.61}\protected@file@percent }
\newlabel{tab:final_model3}{{\M@TitleReference {4.13}{Final values obtained after the parameter search for model 2.\relax }}{55}{Final values obtained after the parameter search for model 2.\relax }{table.caption.61}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Conclusion}{55}{section.4.6}\protected@file@percent }
\@setckpt{chap-3}{
\setcounter{page}{56}
\setcounter{equation}{4}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{@memmarkcntra}{0}
\setcounter{storedpagenumber}{1}
\setcounter{book}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{6}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{vslineno}{0}
\setcounter{poemline}{0}
\setcounter{modulo@vs}{0}
\setcounter{memfvsline}{0}
\setcounter{verse}{0}
\setcounter{chrsinstr}{0}
\setcounter{poem}{0}
\setcounter{newflo@tctr}{4}
\setcounter{@contsubnum}{0}
\setcounter{maxsecnumdepth}{2}
\setcounter{sidefootnote}{0}
\setcounter{pagenote}{0}
\setcounter{pagenoteshadow}{0}
\setcounter{memfbvline}{0}
\setcounter{bvlinectr}{0}
\setcounter{cp@cntr}{0}
\setcounter{ism@mctr}{0}
\setcounter{xsm@mctr}{0}
\setcounter{csm@mctr}{0}
\setcounter{ksm@mctr}{0}
\setcounter{xksm@mctr}{0}
\setcounter{cksm@mctr}{0}
\setcounter{msm@mctr}{0}
\setcounter{xmsm@mctr}{0}
\setcounter{cmsm@mctr}{0}
\setcounter{bsm@mctr}{0}
\setcounter{workm@mctr}{0}
\setcounter{sheetsequence}{66}
\setcounter{lastsheet}{98}
\setcounter{lastpage}{88}
\setcounter{figure}{10}
\setcounter{lofdepth}{1}
\setcounter{table}{13}
\setcounter{lotdepth}{1}
\setcounter{Item}{5}
\setcounter{Hfootnote}{0}
\setcounter{memhycontfloat}{0}
\setcounter{Hpagenote}{0}
\setcounter{bookmark@seq@number}{23}
\setcounter{parentequation}{0}
\setcounter{AlgoLine}{0}
\setcounter{algocfline}{0}
\setcounter{algocfproc}{0}
\setcounter{algocf}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{3}
\setcounter{subtable}{0}
\setcounter{section@level}{1}
}
